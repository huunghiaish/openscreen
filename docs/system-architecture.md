# OpenScreen System Architecture

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron Main Process                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ App lifecycle & window management                      â”‚  â”‚
â”‚  â”‚ â€¢ Tray menu                                             â”‚  â”‚
â”‚  â”‚ â€¢ File system operations (save, export)                 â”‚  â”‚
â”‚  â”‚ â€¢ Screen capture via native APIs                        â”‚  â”‚
â”‚  â”‚ â€¢ IPC request handlers                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†• IPC Messages
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Electron Renderer (React Application)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Window Router (src/App.tsx)                              â”‚  â”‚
â”‚  â”‚ ?windowType=hud-overlay | source-selector | editor       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ HUD Overlay     â”‚  â”‚ Source Selector â”‚  â”‚ Video Editor â”‚   â”‚
â”‚  â”‚ â€¢ Record button â”‚  â”‚ â€¢ Screen list   â”‚  â”‚ â€¢ Timeline   â”‚   â”‚
â”‚  â”‚ â€¢ Device sel.   â”‚  â”‚ â€¢ Window list   â”‚  â”‚ â€¢ Playback   â”‚   â”‚
â”‚  â”‚ â€¢ Status        â”‚  â”‚ â€¢ App list      â”‚  â”‚ â€¢ Export UI  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ React Hooks & State Management                          â”‚  â”‚
â”‚  â”‚ â€¢ useMediaDevices - Camera/mic enumeration              â”‚  â”‚
â”‚  â”‚ â€¢ useScreenRecorder - Recording state                   â”‚  â”‚
â”‚  â”‚ â€¢ Custom hooks for UI state                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Libraries & Utilities                                   â”‚  â”‚
â”‚  â”‚ â€¢ PixiJS - Canvas rendering                             â”‚  â”‚
â”‚  â”‚ â€¢ dnd-timeline - Timeline interaction                   â”‚  â”‚
â”‚  â”‚ â€¢ Exporter - MP4/GIF pipeline                           â”‚  â”‚
â”‚  â”‚ â€¢ platform-utils - macOS detection                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†• Web APIs
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Browser/OS APIs                              â”‚
â”‚  â€¢ navigator.mediaDevices (camera/mic)                          â”‚
â”‚  â€¢ MediaStream API                                              â”‚
â”‚  â€¢ localStorage                                                 â”‚
â”‚  â€¢ File system (via Electron preload)                           â”‚
â”‚  â€¢ Native screen capture (via Electron main)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Process Architecture

### Main Process (Electron)

**Entry**: `electron/main.ts`

**Responsibilities**:
- Application lifecycle (init, ready, quit)
- Create/manage application windows (HUD, Editor, SourceSelector)
- Handle system tray menu
- Intercept file operations and safe writes
- Manage screen capture sessions
- Process IPC requests from renderer

**Key Files**:
- `electron/main.ts` - App entry and initialization
- `electron/windows.ts` - Window creation functions
- `electron/preload.ts` - Secure IPC bridge
- `electron/ipc/handlers.ts` - IPC request handlers

### Renderer Process (React)

**Entry**: `src/App.tsx`

**Window Router**:
```typescript
// In src/App.tsx - routes based on ?windowType query param
if (windowType === 'hud-overlay') return <LaunchWindow />;
if (windowType === 'source-selector') return <SourceSelector />;
return <VideoEditor />; // default
```

**Components by Type**:
- **HUD Overlay** (`src/components/launch/LaunchWindow.tsx`)
  - Recording controls (play/pause/stop)
  - Device selection dropdowns
  - Status display (recording, selected device)

- **Source Selector** (`src/components/launch/SourceSelector.tsx`)
  - List of available screens
  - List of open windows
  - List of running applications
  - Preview of selected source

- **Editor** (`src/components/video-editor/VideoEditor.tsx`)
  - Video playback with PixiJS canvas
  - Timeline with drag-and-drop regions
  - Settings panel for export options
  - Preview of edits in real-time

## Data Flow Architecture

### Recording Session Flow

```
1. HUD Launch Window
   â”œâ”€ useMediaDevices hook
   â”‚  â”œâ”€ Calls navigator.mediaDevices.enumerateDevices()
   â”‚  â”œâ”€ Filters for videoinput/audioinput kinds
   â”‚  â”œâ”€ Listens for 'devicechange' events
   â”‚  â”œâ”€ Persists selection to localStorage
   â”‚  â””â”€ Validates device IDs on selection
   â”‚
   â”œâ”€ User selects camera, microphone, and system audio preference
   â”‚
   â”œâ”€ Source Selector Window
   â”‚  â”œâ”€ Queries main process for available screens/windows
   â”‚  â”œâ”€ User selects display region
   â”‚  â”‚
   â”‚  â””â”€ Click Record
   â”‚     â”œâ”€ Emit 'START_CAPTURE' IPC to main
   â”‚     â”‚  â””â”€ Payload includes optional cameraDeviceId and systemAudioEnabled flag
   â”‚     â”‚
   â”‚     â”œâ”€ Main process initializes capture
   â”‚     â”‚  â”œâ”€ Start screen capture
   â”‚     â”‚  â”œâ”€ If cameraDeviceId: Start camera capture (separate MediaStream)
   â”‚     â”‚  â”œâ”€ Begin microphone audio stream (if enabled)
   â”‚     â”‚  â””â”€ Begin system audio capture (if enabled and macOS 13.2+)
   â”‚     â”‚     â””â”€ Extract audio from ScreenCaptureKit desktop capture
   â”‚     â”‚
   â”‚     â”œâ”€ Recording flows via IPC
   â”‚     â”‚  â”œâ”€ Screen frame data â†’ RECORDINGS_DIR/recording-{timestamp}.webm
   â”‚     â”‚  â”œâ”€ Camera frame data â†’ RECORDINGS_DIR/camera-{timestamp}.webm (if camera enabled)
   â”‚     â”‚  â”œâ”€ Microphone audio â†’ RECORDINGS_DIR/mic-{timestamp}.webm (if mic enabled)
   â”‚     â”‚  â””â”€ System audio â†’ RECORDINGS_DIR/system-audio-{timestamp}.webm (if system audio enabled)
   â”‚     â”‚
   â”‚     â”œâ”€ useSystemAudioCapture Hook (if system audio enabled)
   â”‚     â”‚  â”œâ”€ captureSystemAudio() extracts audio from ScreenCaptureKit
   â”‚     â”‚  â”œâ”€ setupAudioLevelMeter() for VU meter display
   â”‚     â”‚  â”œâ”€ startRecording() captures audio at 192 kbps
   â”‚     â”‚  â””â”€ Runs in parallel with screen recording
   â”‚     â”‚
   â”‚     â”œâ”€ Camera preview overlay shown (optional)
   â”‚     â”‚  â””â”€ useScreenRecorder with cameraDeviceId displays live camera feed
   â”‚     â”‚
   â”‚     â””â”€ User clicks Stop â†’ 'STOP_CAPTURE' IPC
   â”‚        â”œâ”€ Screen recording stops
   â”‚        â”œâ”€ Camera recording stops (if enabled)
   â”‚        â”œâ”€ Microphone audio stops (if enabled)
   â”‚        â”‚  â””â”€ Emit 'store-audio-recording' IPC with mic audio blob
   â”‚        â”œâ”€ System audio stops (if enabled)
   â”‚        â”‚  â””â”€ Emit 'store-system-audio-recording' IPC with system audio blob
   â”‚        â””â”€ All files saved to RECORDINGS_DIR
   â”‚
   â””â”€ Editor Window Opens (Phase 06: Multi-Track Timeline)
      â”œâ”€ Video data loaded from file
      â”œâ”€ buildMediaTracks() resolves all available audio/video paths
      â”‚  â”œâ”€ Call getMicAudioPath(mainVideoPath)
      â”‚  â”œâ”€ Call getSystemAudioPath(mainVideoPath)
      â”‚  â”œâ”€ Reuse cameraVideoPath from Phase 03
      â”‚  â””â”€ Construct MediaTrack[] for each available file
      â”œâ”€ TimelineEditor renders multi-track display
      â”‚  â”œâ”€ MediaTrackRow (Screen) - always present
      â”‚  â”œâ”€ MediaTrackRow (Camera) - if camera-{timestamp}.webm exists
      â”‚  â”œâ”€ MediaTrackRow (Microphone) - if mic-{timestamp}.webm exists
      â”‚  â”œâ”€ MediaTrackRow (System Audio) - if system-audio-{timestamp}.webm exists
      â”‚  â””â”€ Color-coded blocks + waveform patterns for audio tracks
      â””â”€ Each track spans correct duration (startMs â†’ endMs)

2. Video Editing
   â”œâ”€ User interacts with timeline
   â”‚  â”œâ”€ Drag regions for zoom
   â”‚  â”œâ”€ Add annotations
   â”‚  â”œâ”€ Trim video segments
   â”‚  â””â”€ Adjust camera overlay (position/size if present)
   â”‚
   â”œâ”€ PixiJS canvas updates in real-time
   â”‚  â”œâ”€ Renders current frame
   â”‚  â”œâ”€ Applies zoom/effects
   â”‚  â”œâ”€ Overlays camera preview (if present)
   â”‚  â””â”€ Playback synchronized with all timeline tracks
   â”‚
   â””â”€ User Exports
      â”œâ”€ Select export format (MP4, GIF)
      â”œâ”€ Configure settings
      â”œâ”€ Emit 'EXPORT_VIDEO' IPC
      â”œâ”€ Main process:
      â”‚  â”œâ”€ Render all frames with effects
      â”‚  â”œâ”€ Composite camera overlay onto screen frames (if present)
      â”‚  â”œâ”€ Mux video + audio tracks
      â”‚  â””â”€ Write file to disk
      â””â”€ Export complete
```

## Component Hierarchy

### Launch Window (HUD Overlay)

```
LaunchWindow (Main HUD component)
â”œâ”€â”€ useMediaDevices Hook (device enumeration)
â”œâ”€â”€ useMicrophoneCapture Hook (audio level metering)
â”œâ”€â”€ useSelectedSource Hook (source name display)
â”œâ”€â”€ useRecordingTimer Hook (elapsed time display)
â”œâ”€â”€ useCameraOverlay Hook (camera window management)
â”‚
â”œâ”€â”€ RecordButton + Status Display
â”‚   â”œâ”€â”€ Recording timer (MM:SS format)
â”‚   â””â”€â”€ Selected source name
â”‚
â”œâ”€â”€ CameraSettingsDropdown
â”‚   â”œâ”€â”€ DeviceDropdown (base component)
â”‚   â”œâ”€â”€ None / Camera list options
â”‚   â””â”€â”€ Permission request handling
â”‚
â”œâ”€â”€ MicSettingsDropdown
â”‚   â”œâ”€â”€ DeviceDropdown (base component)
â”‚   â”œâ”€â”€ AudioLevelMeter (header content - real-time VU meter)
â”‚   â”œâ”€â”€ None / Microphone list options
â”‚   â””â”€â”€ Audio level display (0-100, dB scale)
â”‚
â””â”€â”€ SystemAudioToggle
    â”œâ”€â”€ Toggle button (enabled/disabled)
    â””â”€â”€ Platform check (macOS 13.2+ required)
```

**DeviceDropdown (Base Component)**:
- Reusable dropdown for device selection
- Keyboard navigation: Arrow Up/Down, Enter/Space, Escape
- ARIA accessibility: aria-label, aria-expanded, aria-selected
- Glass morphism styling (HUD aesthetic)
- Opens upward to avoid obscuring controls
- Optional headerContent slot (e.g., audio meters)

### Video Editor

```
VideoEditor
â”œâ”€â”€ VideoPlayback (PixiJS Canvas)
â”‚   â”œâ”€â”€ FrameRenderer
â”‚   â”œâ”€â”€ CameraPipOverlay (if camera recorded)
â”‚   â”‚   â””â”€â”€ Synchronized with main video (play/pause/seek)
â”‚   â””â”€â”€ ZoomEffectApplier
â”œâ”€â”€ TimelineEditor
â”‚   â”œâ”€â”€ MediaTrackRow (Screen video)
â”‚   â”‚   â”œâ”€â”€ Label: â–¶ Screen
â”‚   â”‚   â””â”€â”€ Block: Blue (#3b82f6), solid color
â”‚   â”œâ”€â”€ MediaTrackRow (Camera video) [optional]
â”‚   â”‚   â”œâ”€â”€ Label: ğŸ¥ Camera
â”‚   â”‚   â””â”€â”€ Block: Purple (#8b5cf6), solid color
â”‚   â”œâ”€â”€ MediaTrackRow (Microphone audio) [optional]
â”‚   â”‚   â”œâ”€â”€ Label: ğŸ¤ Microphone
â”‚   â”‚   â””â”€â”€ Block: Green (#22c55e), gradient waveform pattern
â”‚   â”œâ”€â”€ MediaTrackRow (System audio) [optional]
â”‚   â”‚   â”œâ”€â”€ Label: ğŸ”Š System Audio
â”‚   â”‚   â””â”€â”€ Block: Amber (#f59e0b), gradient waveform pattern
â”‚   â””â”€â”€ ZoomRegionEditor (existing zoom regions)
â””â”€â”€ SettingsPanel (Tabs: General, Export, Annotations)
    â”œâ”€â”€ CameraPipSettings (if camera recorded)
    â”‚   â”œâ”€â”€ EnableToggle
    â”‚   â”œâ”€â”€ PositionSelector
    â”‚   â”œâ”€â”€ SizeSelector
    â”‚   â”œâ”€â”€ ShapeSelector (4 shapes: rounded-rectangle, rectangle, square, circle)
    â”‚   â””â”€â”€ BorderRadiusSlider (only shown for rounded-rectangle shape)
    â”œâ”€â”€ CropControl
    â”œâ”€â”€ AnnotationSettingsPanel
    â”œâ”€â”€ VideoSettings
    â”‚   â”œâ”€â”€ ShadowIntensity
    â”‚   â”œâ”€â”€ BlurToggle
    â”‚   â”œâ”€â”€ MotionBlurToggle
    â”‚   â”œâ”€â”€ BorderRadiusControl
    â”‚   â””â”€â”€ PaddingControl
    â””â”€â”€ ExportSettings
        â”œâ”€â”€ FormatSelector
        â”œâ”€â”€ QualityControl
        â”œâ”€â”€ GifSettings
        â””â”€â”€ FilenameInput
```

## Multi-Track Timeline Architecture (Phase 06)

See dedicated documentation: [Timeline & Multi-Track Architecture](./timeline-architecture.md)

Covers:
- Track display system with responsive layout
- MediaTrack type system and interfaces
- Visual design (color scheme, icons, waveform visualization)
- File path resolution pattern
- Track loading process
- Component integration
- Audio waveform MVP implementation
- Security considerations
- Performance notes

## Export Pipeline Architecture

### Phase 4: Frame Source Abstraction (NEW)

**Purpose**: Unified interface for frame extraction with automatic WebCodecs/HTMLVideo selection and trim region handling.

**FrameSource Interface** (`src/lib/exporter/frame-source.ts`, 149 lines):
- Abstraction enabling seamless switching between WebCodecs and HTMLVideoElement backends
- Automatic fallback: tries WebCodecs first, falls back if unsupported or initialization fails
- Built-in trim region mapping via `TrimTimeMapper`
- VideoFrame ownership contract: caller owns frames, must call `close()` to release GPU memory

**Key Types**:
```typescript
interface FrameSourceConfig {
  videoUrl: string;
  frameRate: number;
  trimRegions?: TrimRegion[];
  debug?: boolean;
}

interface FrameSourceResult {
  width: number;
  height: number;
  duration: number;  // Effective duration (excluding trims)
  mode: 'webcodecs' | 'htmlvideo';
}

interface FrameSource {
  initialize(): Promise<FrameSourceResult>
  getFrame(frameIndex, effectiveTimeMs): Promise<VideoFrame>
  destroy(): void
  getStats(): FrameSourceStats
}
```

**Factory Function**:
```typescript
const { source, result } = await createFrameSource(config);
// Returns WebCodecsFrameSource if available, else HTMLVideoFrameSource
```

**WebCodecsFrameSource** (`src/lib/exporter/webcodecs-frame-source.ts`, 338 lines):
- High-performance implementation (~5ms per frame)
- Pipeline: VideoDemuxer â†’ VideoDecoderService â†’ DecodedFrameBuffer
- Features:
  - Proactive decode-ahead loop with backpressure management
  - Trim time mapping via `TrimTimeMapper`
  - Frame index-based waiter notification system
  - Frame availability detection with error propagation
  - Statistics: frames retrieved, average/peak retrieval times

**HTMLVideoFrameSource** (`src/lib/exporter/htmlvideo-frame-source.ts`, 144 lines):
- Fallback implementation (~100-140ms per frame)
- Wraps `PrefetchManager` with `FrameSource` interface
- Maintains compatibility with existing export pipeline
- VideoFrame creation from HTMLVideoElement
- Same statistics tracking as WebCodecs path

**TrimTimeMapper Utility** (`src/lib/exporter/trim-time-mapper.ts`, 109 lines):
- Converts between effective time (excluding trims) and source time (original timeline)
- Used by both FrameSource implementations
- Methods:
  - `mapEffectiveToSourceTime()` - Timeline offset accounting for trims
  - `getEffectiveDuration()` - Duration with trims excluded
  - `getTotalTrimDurationMs/Sec()` - Trim metadata
  - `hasTrims()`, `getTrimCount()` - State queries

**Integration in VideoExporter**:
- Creates FrameSource during export initialization
- Passes to RenderCoordinator or FrameRenderer
- Receives VideoFrames with automatic trim mapping
- Destroys source on export cleanup

### Phase 1: Video Demuxer (NEW)

The export pipeline now includes a dedicated video demuxer for efficient frame extraction:

**VideoDemuxer Class** (`src/lib/exporter/video-demuxer.ts`, 320 LOC)
- Wraps mediabunny library for container format handling
- Supports MP4, WebM, Matroska, QuickTime containers
- Key responsibilities:
  1. **Initialization**: Load video file, extract codec metadata, validate with WebCodecs API
  2. **Frame Extraction**: Async iterator interface yields EncodedVideoChunks in decode order
  3. **Keyframe Seeking**: Locate nearest keyframe at/before requested timestamp
  4. **Memory Management**: Async generators prevent full-file buffering
  5. **Resource Cleanup**: Proper disposal of mediabunny Input and URL resources

**Public API**:
```typescript
class VideoDemuxer {
  async initialize(): Promise<DemuxerResult>
  async *getChunksFromTimestamp(startTime, endTime): AsyncGenerator<EncodedVideoChunk>
  async seekToKeyframe(timestamp): Promise<number | null>
  getDecoderConfig(): VideoDecoderConfig | null
  isInitialized(): boolean
  destroy(): void
}

// Factory for Blob/File inputs
async function createDemuxerFromBlob(blob): Promise<{ demuxer, result }>
```

**DemuxerResult Metadata**:
- `config: VideoDecoderConfig` - Codec info (for WebCodecs setup)
- `width, height: number` - Video dimensions
- `duration: number` - Total duration in seconds
- `frameCount, fps: number` - Estimated frame metrics

**Integration Points**:
- Used by VideoExporter for reading source video frames
- Provides EncodedVideoChunk stream for WebCodecs VideoDecoder
- Supports trim region time mapping via PrefetchManager
- Factory function handles Blobâ†’URL lifecycle management

**Testing** (313 LOC):
- Initialization with valid/invalid codecs
- Chunk generation and endTime boundary testing
- Keyframe seeking accuracy
- Resource cleanup (idempotent destroy, URL revocation)
- Error handling (destroyed state validation)

### Phase 2: Video Decoder Service (NEW)

**VideoDecoderService Class** (`src/lib/exporter/video-decoder-service.ts`, 337 LOC)

Hardware-accelerated video decoding using WebCodecs VideoDecoder API with automatic backpressure management.

**Key Features**:
- **Hardware Acceleration**: Automatic GPU acceleration (VideoToolbox on macOS, MediaFoundation on Windows)
- **Backpressure Management**: Monitors `decodeQueueSize` to prevent memory exhaustion and queue overflow
- **Frame Output Callback**: Decoded frames delivered in presentation order
- **Performance Monitoring**: Decode timing stats and hardware acceleration detection

**Configuration**:
```typescript
interface DecoderServiceConfig {
  maxQueueSize?: number;  // Default: 8 (threshold before backpressure applied)
  debug?: boolean;        // Enable debug logging
}
```

**Public API**:
```typescript
class VideoDecoderService {
  constructor(config?: DecoderServiceConfig)
  async configure(config: VideoDecoderConfig): Promise<boolean>
  canAcceptChunk(): boolean
  async waitForSpace(): Promise<void>
  async decode(chunk: EncodedVideoChunk): Promise<void>
  async flush(): Promise<void>
  close(): void
  async reset(): Promise<boolean>
  setFrameCallback(callback: FrameCallback): void
  getStats(): DecoderStats
  getState(): 'unconfigured' | 'configured' | 'closed'
  getLastError(): Error | null
}
```

**Usage Example**:
```typescript
const service = new VideoDecoderService({ maxQueueSize: 8 });
service.setFrameCallback((frame, timestamp) => {
  // Process frame
  frame.close(); // Must close to release GPU memory
});

await service.configure(decoderConfig);

for await (const chunk of demuxer.getChunksFromTimestamp(0)) {
  await service.decode(chunk);  // Applies backpressure automatically
}

await service.flush();
service.close();
```

**Backpressure Mechanism**:
- `canAcceptChunk()`: Returns false if `decodeQueueSize >= maxQueueSize`
- `waitForSpace()`: Returns immediately if space available, else waits for dequeue event
- `decode()`: Internally calls `waitForSpace()` before submitting chunk
- Event listener on 'dequeue' event resolves waiting promises

**Performance Statistics** (`DecoderStats`):
- `framesDecoded` - Successfully decoded frame count
- `framesDropped` - Frames dropped due to errors
- `averageDecodeTime` - Mean decode time in milliseconds
- `queueSize` - Current decode queue size
- `isHardwareAccelerated` - Estimated hardware acceleration (avg decode time <5ms with >10 frames)

**Integration Points**:
- Used by VideoExporter in Phase 2+ for decoding video frames from demuxer
- Replaces synchronous HTML5 video element seeking for performance
- Enables true hardware-accelerated export pipeline

### Phase 3: Decoded Frame Buffer (NEW)

**DecodedFrameBuffer Class** (`src/lib/exporter/decoded-frame-buffer.ts`, 488 LOC)

Memory-bounded buffer for decoded VideoFrames between VideoDecoderService output and worker consumption with frame index-based lookup.

**Key Features**:
- **Frame Storage**: Map of VideoFrames indexed by timestamp for O(1) lookup
- **Index Mapping**: Converts frame sequence numbers to timestamps using frame rate
- **Memory Bounded**: Max buffer size (default: 16 frames) with automatic eviction
- **Frame Eviction**: Oldest frames closed and removed when buffer full
- **Backpressure**: Promise-based waiting for buffer space
- **Timestamp Tolerance**: Configurable tolerance (microseconds) for VFR content handling
- **Statistics**: Tracks added, consumed, evicted frame counts and buffer bounds

**Configuration**:
```typescript
interface FrameBufferConfig {
  maxFrames?: number;        // Default: 16 (evict oldest when full)
  frameRate: number;         // Required for indexâ†’timestamp conversion
  timestampTolerance?: number;  // Default: half frame duration (Âµs)
  debug?: boolean;           // Enable debug logging
}
```

**Public API**:
```typescript
class DecodedFrameBuffer {
  // Producer methods (from VideoDecoderService callback)
  addFrame(frame: VideoFrame): void
  isFull(): boolean
  async waitForSpace(): Promise<void>

  // Consumer methods (from workers requesting frames)
  hasFrame(frameIndex: number): boolean
  getFrame(frameIndex: number): VideoFrame | null      // Non-destructive
  consumeFrame(frameIndex: number): VideoFrame | null  // Removes from buffer

  // Lifecycle methods
  flush(): VideoFrame[]  // Return all frames without closing
  reset(): void          // Close all frames, clear state
  destroy(): void        // Final cleanup

  // Monitoring
  getStats(): BufferStats
  get size(): number
}
```

**Usage Pattern**:
```typescript
const buffer = new DecodedFrameBuffer({ frameRate: 30, maxFrames: 16 });

// Producer: decoder service adds frames
decoderService.setFrameCallback((frame) => {
  if (buffer.isFull()) {
    await buffer.waitForSpace();
  }
  buffer.addFrame(frame);
});

// Consumer: workers fetch frames by index
if (buffer.hasFrame(frameIndex)) {
  const frame = buffer.consumeFrame(frameIndex);
  await worker.render(frame);  // Zero-copy transfer
  frame.close();  // Consumer responsible for cleanup
}
```

**Memory Management**:
- **Eviction Policy**: FIFO (oldest frame first) when maxFrames exceeded
- **GPU Memory**: `frame.close()` called on evicted frames to release GPU resources
- **VFR Handling**: Timestamp tolerance parameter accommodates Variable Frame Rate content drift
  - For VFR: Recommend tolerance = 1-1.5x frame duration (e.g., 33-50ms at 30fps)
  - Default tolerance = half frame duration (handles minor timing variation)

**Integration Points**:
- Sits between VideoDecoderService output and RenderCoordinator input
- Enables decoupling of decode and render rates for pipeline flexibility
- Supports zero-copy VideoFrame transfer to workers
- Backpressure prevents decoder from outpacing worker consumption

**Testing** (34 unit tests):
- Frame addition, lookup, and consumption
- Indexâ†’timestamp conversion with tolerance
- Buffer full eviction behavior
- Backpressure waiting mechanism
- Batch operations and flush behavior
- VFR timestamp handling

### Phase 2: Parallel Rendering Workers

The export pipeline uses Web Workers for parallel frame rendering:
1. **Worker Pool** (4 workers, fixed pool size per validation)
2. **Frame Distribution** via RenderCoordinator
3. **In-Order Reassembly** via FrameReassembler
4. **Zero-Copy Transfer** of VideoFrame objects
5. **Graceful Fallback** to single-threaded rendering if workers unavailable

### Phase 1: Frame Pipeline Optimization

The export pipeline has been optimized to eliminate busy-wait polling and reduce memory churn through:
1. **Promise-based backpressure** via EncodeQueue (replaces busy-wait)
2. **Dual video element prefetching** (overlaps seek latency with rendering)
3. **Texture caching optimization** (reuses GPU memory instead of destroy/recreate)
4. **AbortController cleanup** (prevents deadlocks on seek timeout)
5. **Performance telemetry** (tracks queue depth, prefetch hits, seek counts)

### Parallel Rendering Flow (Phase 2)

```
VideoExporter / GifExporter (with useParallelRendering: true)
â”‚
â”œâ”€ Initialize components
â”‚  â”œâ”€ RenderCoordinator (with WorkerPool)
â”‚  â”‚  â”œâ”€ WorkerPool (4 workers, fixed count)
â”‚  â”‚  â”‚  â”œâ”€ Worker 0-3: Web Worker instances
â”‚  â”‚  â”‚  â”œâ”€ OffscreenCanvas per worker
â”‚  â”‚  â”‚  â””â”€ PixiJS renderer in each worker
â”‚  â”‚  â”œâ”€ FrameReassembler (collects rendered frames in-order)
â”‚  â”‚  â””â”€ Fallback: Single-threaded FrameRenderer if workers fail
â”‚  â”‚
â”‚  â”œâ”€ EncodeQueue (Promise backpressure, max: 6 frames)
â”‚  â”œâ”€ PrefetchManager (dual video elements for overlap)
â”‚  â”œâ”€ AudioFileDecoders (mic, system)
â”‚  â””â”€ VideoEncoder + AudioEncoder
â”‚
â”œâ”€ Main export loop (per frame)
â”‚  â”‚
â”‚  â”œâ”€ Await EncodeQueue.waitForSpace()
â”‚  â”‚  â””â”€ Returns immediately if space, else Promise backpressure
â”‚  â”‚
â”‚  â”œâ”€ Get frame via PrefetchManager.getFrame()
â”‚  â”‚  â”œâ”€ Check if prefetched frame available (overlap from prev iteration)
â”‚  â”‚  â”œâ”€ If prefetch miss: Seek synchronously with 5s timeout
â”‚  â”‚  â””â”€ Start async prefetch of next frame on alternate video element
â”‚  â”‚
â”‚  â”œâ”€ Distribute to RenderCoordinator.renderFrame()
â”‚  â”‚  â”œâ”€ If parallel mode:
â”‚  â”‚  â”‚  â”œâ”€ Find idle worker from pool
â”‚  â”‚  â”‚  â”œâ”€ Send render config + frame data via postMessage
â”‚  â”‚  â”‚  â”œâ”€ Transfer VideoFrame as Transferable (zero-copy)
â”‚  â”‚  â”‚  â””â”€ Track pending render with index
â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€ If fallback mode:
â”‚  â”‚     â””â”€ Single-threaded FrameRenderer.render()
â”‚  â”‚
â”‚  â”œâ”€ FrameReassembler collects rendered frames
â”‚  â”‚  â”œâ”€ Wait for frames in-order (index 0, 1, 2, ...)
â”‚  â”‚  â”œâ”€ Buffer out-of-order arrivals (max 32 frames)
â”‚  â”‚  â””â”€ Emit ordered frames for encoding
â”‚  â”‚
â”‚  â”œâ”€ Submit frame to VideoEncoder
â”‚  â”œâ”€ Increment EncodeQueue.increment()
â”‚  â”‚
â”‚  â””â”€ Process pending audio frames (mixed mic + system audio)
â”‚     â”œâ”€ Mix audio buffers asynchronously
â”‚     â”œâ”€ Encode audio chunk
â”‚     â””â”€ Await AudioEncodeQueue.waitForSpace() for backpressure
â”‚
â”œâ”€ Encoder output loop (runs in parallel)
â”‚  â”œâ”€ VideoEncoder.output callback fires
â”‚  â”‚  â”œâ”€ Receive encoded chunk
â”‚  â”‚  â”œâ”€ Queue for muxing
â”‚  â”‚  â””â”€ Call EncodeQueue.onChunkOutput() (unblocks waitForSpace)
â”‚  â”‚
â”‚  â””â”€ AudioEncoder.output callback fires
â”‚     â””â”€ Similar flow for audio chunks
â”‚
â”œâ”€ Mux final frames with audio tracks
â”‚  â””â”€ Combined MP4 output
â”‚
â””â”€ Performance reporting
   â”œâ”€ RenderCoordinator stats: parallel/fallback mode, worker pool stats
   â”œâ”€ FrameReassembler stats: buffer size, out-of-order frames
   â”œâ”€ PrefetchManager stats: seekCount, prefetchHits, prefetchMisses, hitRate
   â”œâ”€ EncodeQueue stats: peakSize, totalEncoded, totalWaits, pendingWaits
   â””â”€ Total timings for optimization tracking
```

### Frame Pipeline Flow (Phase 1)

```
VideoExporter / GifExporter (with useParallelRendering: false)
â”‚
â”œâ”€ Initialize components
â”‚  â”œâ”€ FrameRenderer (with texture caching)
â”‚  â”œâ”€ EncodeQueue (Promise backpressure, max: 6 frames)
â”‚  â”œâ”€ PrefetchManager (dual video elements for overlap)
â”‚  â”œâ”€ AudioFileDecoders (mic, system)
â”‚  â””â”€ VideoEncoder + AudioEncoder
â”‚
â”œâ”€ Main export loop (per frame)
â”‚  â”‚
â”‚  â”œâ”€ Await EncodeQueue.waitForSpace()
â”‚  â”‚  â””â”€ Returns immediately if space, else Promise backpressure
â”‚  â”‚
â”‚  â”œâ”€ Get frame via PrefetchManager.getFrame()
â”‚  â”‚  â”œâ”€ Check if prefetched frame available (overlap from prev iteration)
â”‚  â”‚  â”œâ”€ If prefetch miss: Seek synchronously with 5s timeout
â”‚  â”‚  â””â”€ Start async prefetch of next frame on alternate video element
â”‚  â”‚
â”‚  â”œâ”€ FrameRenderer.render() processes frame
â”‚  â”‚  â”œâ”€ Decode video frame from source
â”‚  â”‚  â”œâ”€ Render effects (zoom, crop, blur, shadow)
â”‚  â”‚  â”œâ”€ Render annotations
â”‚  â”‚  â”œâ”€ Apply texture caching (update source, avoid destroy/recreate)
â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€ If Camera PiP enabled:
â”‚  â”‚     â””â”€ CameraPipRenderer composites PiP onto frame
â”‚  â”‚
â”‚  â”œâ”€ Submit frame to VideoEncoder
â”‚  â”œâ”€ Increment EncodeQueue.increment()
â”‚  â”‚
â”‚  â””â”€ Process pending audio frames (mixed mic + system audio)
â”‚     â”œâ”€ Mix audio buffers asynchronously
â”‚     â”œâ”€ Encode audio chunk
â”‚     â””â”€ Await AudioEncodeQueue.waitForSpace() for backpressure
â”‚
â”œâ”€ Encoder output loop (runs in parallel)
â”‚  â”œâ”€ VideoEncoder.output callback fires
â”‚  â”‚  â”œâ”€ Receive encoded chunk
â”‚  â”‚  â”œâ”€ Queue for muxing
â”‚  â”‚  â””â”€ Call EncodeQueue.onChunkOutput() (unblocks waitForSpace)
â”‚  â”‚
â”‚  â””â”€ AudioEncoder.output callback fires
â”‚     â””â”€ Similar flow for audio chunks
â”‚
â”œâ”€ Mux final frames with audio tracks
â”‚  â””â”€ Combined MP4 output
â”‚
â””â”€ Performance reporting
   â”œâ”€ PrefetchManager stats: seekCount, prefetchHits, prefetchMisses, hitRate
   â”œâ”€ EncodeQueue stats: peakSize, totalEncoded, totalWaits, pendingWaits
   â””â”€ Total timings for optimization tracking
```

### Key Components

#### EncodeQueue (NEW)

**Location**: `src/lib/exporter/encode-queue.ts` (132 lines)

**Purpose**: Event-driven queue with Promise-based backpressure to replace busy-wait polling.

**Key Methods**:
- `async waitForSpace()` - Returns immediately if space, else Promises until chunk output
- `increment()` - Called when frame submitted (increments queue size)
- `onChunkOutput()` - Called by encoder output callback (decrements, resolves waiters)
- `getStats()` - Performance metrics (peak size, total encoded, waits)
- `reset()` - Clear state for new export

**Configuration**:
- Default `maxSize: 6` (optimal for hardware encoders)
- Configurable `debug` logging
- Tracks peak queue depth for diagnostics

**Performance Impact**:
- Replaces `while (queue >= MAX) await setTimeout(0)` busy-wait
- Reduced CPU spinning during backpressure
- Better responsiveness to encoder output events

#### PrefetchManager (NEW)

**Location**: `src/lib/exporter/prefetch-manager.ts` (314 lines)

**Purpose**: Double-buffered video element strategy to overlap seek latency (~50-100ms) with frame rendering.

**Key Methods**:
- `async initialize()` - Create both video elements, return metadata
- `async getFrame(frameIndex, effectiveTimeMs)` - Get video element at time
- `destroy()` - Cleanup and abort pending operations

**Optimization Strategy**:
- **Element A** (current frame): Used for immediate rendering
- **Element B** (prefetch): Asynchronously seeks to next frame
- On next iteration, elements swap roles
- Seek latency overlaps with rendering computation

**Prefetch Hit Rate**:
- High hit rate (>90%) when processing consecutive frames
- Miss handling: Synchronous seek with graceful timeout
- Seek timeout: 5s default (prevents deadlock on corrupted videos)

**Trim Region Support**:
- Automatically maps effective time (excluding trims) to source time
- Handles arbitrary trim regions with overlap detection

#### FrameRenderer Texture Caching

**Location**: `src/lib/exporter/frameRenderer.ts`

**Change**: Optimized texture management in frame loop.

**Before**:
```javascript
const oldTexture = this.videoSprite.texture;
const newTexture = Texture.from(videoFrame);
this.videoSprite.texture = newTexture;
oldTexture.destroy(true);  // Immediate GPU memory free
```

**After**:
```javascript
const newTexture = Texture.from(videoFrame);
const oldTexture = this.videoSprite.texture;
this.videoSprite.texture = newTexture;
// Only destroy if different reference (avoid double-free)
if (oldTexture !== newTexture && oldTexture !== Texture.EMPTY) {
  oldTexture.destroy(true);
}
```

**Impact**:
- Reduces GPU memory churn per frame
- Reuses texture memory more efficiently
- Improves frame submission throughput

#### WorkerPool (NEW - Phase 2)

**Location**: `src/lib/exporter/worker-pool.ts`

**Purpose**: Manages pool of 4 Web Workers for parallel frame rendering.

**Key Features**:
- Fixed worker count: 4 workers (validated as optimal for M4)
- Worker state tracking: busy/idle status per worker
- OffscreenCanvas per worker: Isolated rendering surfaces
- Error propagation: Worker crashes don't deadlock pipeline
- Graceful shutdown: Cleanup all workers on destroy

**Public Methods**:
- `constructor(config: WorkerPoolConfig)` - Initialize pool config
- `async initialize(renderConfig)` - Create workers and send init messages
- `async renderFrame(frameIndex, renderRequest)` - Dispatch frame to idle worker
- `async waitForIdle()` - Block until worker available
- `getStats(): WorkerPoolStats` - Query pool performance metrics
- `destroy()` - Cleanup all workers and listeners

**Worker Lifecycle**:
1. Create Worker from bundled `render-worker.ts`
2. Create OffscreenCanvas with render dimensions
3. Send init message with canvas + render config (Transferable)
4. Worker sets up PixiJS renderer with OffscreenCanvas
5. Send render requests with frame data as Transferable
6. Worker processes frame and sends back rendered canvas
7. Main thread receives rendered frame and marks worker idle
8. On destroy: Terminate all workers

#### RenderCoordinator (NEW - Phase 2)

**Location**: `src/lib/exporter/render-coordinator.ts`

**Purpose**: Orchestrates parallel rendering with fallback to single-threaded.

**Key Features**:
- Parallel/fallback modes (automatic detection)
- Frame distribution to worker pool
- In-order frame reassembly
- Zero-copy VideoFrame transfer
- Graceful degradation if workers unavailable

**Public Methods**:
- `constructor(config: RenderCoordinatorConfig)` - Initialize with render settings
- `async initialize()` - Setup workers (with fallback)
- `async renderFrame(frameIndex, sourceFrame)` - Distribute frame to pool
- `async waitForAllFrames()` - Block until all pending renders complete
- `getStats(): CoordinatorStats` - Query rendering stats
- `destroy()` - Cleanup all resources

**Fallback Strategy**:
- Checks for Worker support via `typeof Worker`
- Initializes single-threaded FrameRenderer if workers unavailable
- Transparently switches modes (parallel vs. fallback)
- Reports stats with `mode: 'parallel' | 'fallback'`

#### FrameReassembler (NEW - Phase 2)

**Location**: `src/lib/exporter/frame-reassembler.ts`

**Purpose**: Collects out-of-order rendered frames and emits in-order.

**Key Features**:
- In-order collection: Guarantees frame sequence (index 0, 1, 2, ...)
- Out-of-order buffering: Holds frames arriving ahead of sequence
- Max buffer size: 32 frames (prevents unbounded growth)
- Automatic emission: Yields frames as soon as sequence is available
- Performance tracking: Buffers size, out-of-order counts

**Public Methods**:
- `async addFrame(frameIndex, frame)` - Collect rendered frame
- `async getNextFrame()` - Block until next in-sequence frame available
- `getStats(): ReassemblerStats` - Query reassembler metrics
- `reset()` - Clear state for new export session

**Buffering Example**:
```
Received: [0, 2, 1, 3, ...]
Expected sequence: 0, 1, 2, 3

Step 1: addFrame(0, data) â†’ emit immediately â†’ nextExpected = 1
Step 2: addFrame(2, data) â†’ buffer (ahead of sequence)
Step 3: addFrame(1, data) â†’ emit â†’ emit buffered[2] â†’ nextExpected = 3
Step 4: addFrame(3, data) â†’ emit â†’ nextExpected = 4
```

#### Worker Types & Messages (NEW - Phase 2)

**Location**: `src/lib/exporter/workers/worker-types.ts`

**Key Types**:
- `WorkerRenderConfig` - Render settings (canvas size, effects, regions)
- `WorkerRenderRequest` - Single frame render request (frameIndex, sourceFrame)
- `RenderedWorkerResponse` - Rendered frame result (frameIndex, canvas, transferable)
- `WorkerToMainMessage` - Union of all workerâ†’main messages

**Message Protocol**:
1. Main â†’ Worker: `{ type: 'INIT', renderConfig, canvas }` (Transferable)
2. Worker â†’ Main: `{ type: 'READY' }`
3. Main â†’ Worker: `{ type: 'RENDER', renderRequest, sourceFrame }` (Transferable)
4. Worker â†’ Main: `{ type: 'RENDERED', frameIndex, canvas }` (Transferable)

#### Worker Entry Point (NEW - Phase 2)

**Location**: `src/lib/exporter/workers/render-worker.ts`

**Purpose**: Web Worker entry point that sets up PixiJS renderer.

**Workflow**:
1. Listen for INIT message with OffscreenCanvas
2. Create WorixiRenderer with canvas + render config
3. Send READY message
4. Listen for RENDER messages in loop
5. Call workerRenderer.render(sourceFrame, frameIndex, effects)
6. Send RENDERED message with result canvas

**Key Details**:
- Uses WorkerPixiRenderer for frame rendering
- Transfers canvas back via Transferable (zero-copy)
- Async rendering awaits frame decode completion
- Error handling: Logs and sends ERROR message

### Camera PiP Export Pipeline

```
VideoExporter / GifExporter (with frame pipeline optimization)
â”‚
â”œâ”€ Initialize FrameRenderer
â”‚  â””â”€ Passes cameraExportConfig if camera video present
â”‚
â”œâ”€ Frame pipeline optimization enabled:
â”‚  â”œâ”€ EncodeQueue manages backpressure
â”‚  â”œâ”€ PrefetchManager overlaps seek latency
â”‚  â””â”€ Texture caching reduces GPU churn
â”‚
â”œâ”€ FrameRenderer processes each frame
â”‚  â”‚
â”‚  â”œâ”€ Decode video frame from source
â”‚  â”œâ”€ Render effects (zoom, crop, blur, shadow)
â”‚  â”œâ”€ Render annotations
â”‚  â”‚
â”‚  â””â”€ If Camera PiP enabled:
â”‚     â”‚
â”‚     â”œâ”€ CameraPipRenderer.render(ctx, canvasWidth, canvasHeight, timeMs)
â”‚     â”‚  â”œâ”€ Seek camera video to current time
â”‚     â”‚  â”œâ”€ Extract camera frame to offscreen canvas
â”‚     â”‚  â”œâ”€ Calculate PiP position (based on corner setting)
â”‚     â”‚  â”‚  â”œâ”€ Apply 2% margin from edge
â”‚     â”‚  â”‚  â””â”€ Size from preset percentage (15%, 22%, 30%)
â”‚     â”‚  â”œâ”€ Create clipping path (rounded rectangle for border radius)
â”‚     â”‚  â”œâ”€ Draw camera frame mirrored (natural camera orientation)
â”‚     â”‚  â””â”€ Draw semi-transparent white border (3px)
â”‚     â”‚
â”‚     â””â”€ Graceful handling if camera video ends early
â”‚        â””â”€ Stop rendering PiP for remaining frames
â”‚
â”œâ”€ Mux final frames with audio tracks
â””â”€ Write output file (MP4 or GIF)
```

### CameraPipRenderer Class

**Location**: `src/lib/exporter/camera-pip-renderer.ts` (173 lines)

**Public Methods**:
- `constructor(config: CameraExportConfig)` - Initialize with camera video URL and PiP settings
- `async initialize(): Promise<boolean>` - Load camera video, prepare offscreen canvas. Returns success status.
- `isReady(): boolean` - Check if renderer can process frames
- `getDuration(): number` - Get camera video duration (seconds)
- `async render(ctx, canvasWidth, canvasHeight, timeMs): Promise<void>` - Composite PiP onto frame at time
- `destroy(): void` - Cleanup resources (video element, canvas)

**Private State**:
- `cameraVideo: HTMLVideoElement | null` - Loaded camera video
- `cameraCanvas: HTMLCanvasElement | null` - Offscreen canvas for frame extraction
- `cameraCtx: CanvasRenderingContext2D | null` - 2D context for drawing
- `config: CameraExportConfig` - Configuration (video URL, PiP settings)

**Rendering Details**:
- Time sync: Seeks camera to `timeMs / 1000` before rendering
- Position calculation: Corner-based placement with dynamic margins (2% of canvas width)
- Shape support: 4 configurable shapes via `getShapeParams()` helper
  - `rounded-rectangle`: Original aspect ratio, configurable border radius (0-50%)
  - `rectangle`: Original aspect ratio, no rounding
  - `square`: 1:1 aspect (center-cropped), no rounding
  - `circle`: 1:1 aspect (center-cropped), 50% rounding for full circle
- Center-crop: Applied for square/circle shapes to maintain 1:1 aspect ratio
- Clipping: Uses `roundRect()` with calculated radius based on shape
- Mirroring: Applied via `scale(-1, 1)` transform for natural appearance
- Border: White semi-transparent stroke (rgba 255,255,255,0.2), 3px width
- Early termination: Stops rendering if camera duration exceeded

### Integration Points

**In FrameRenderer**:
- Instantiated if `config.cameraExport` provided
- Called during frame render loop: `await cameraPipRenderer.render(...)`
- Cleanup in destroy: `cameraPipRenderer?.destroy()`

**In VideoExporter/GifExporter**:
- Config props: `cameraVideoUrl`, `cameraPipConfig`
- Passed to FrameRenderer as `cameraExport: CameraExportConfig`

**Type System**:
```typescript
interface CameraExportConfig {
  videoUrl: string;           // Path to camera video file
  pipConfig: CameraPipConfig;  // Position, size, border radius
}

// From types.ts (reused from editor)
interface CameraPipConfig {
  enabled: boolean;
  position: 'top-left' | 'top-right' | 'bottom-left' | 'bottom-right';
  size: 'small' | 'medium' | 'large';
  shape: 'rounded-rectangle' | 'rectangle' | 'square' | 'circle';
  borderRadius: number;  // 0-100%, only used for rounded-rectangle
}
```

## Media Device Infrastructure

### Device Enumeration

```
useMediaDevices Hook
â”‚
â”œâ”€ Initial Load (useEffect)
â”‚  â”œâ”€ Call navigator.mediaDevices.enumerateDevices()
â”‚  â”œâ”€ Filter by kind: 'videoinput' â†’ cameras[]
â”‚  â”œâ”€ Filter by kind: 'audioinput' â†’ microphones[]
â”‚  â”œâ”€ Restore from localStorage if available
â”‚  â””â”€ Validate restored IDs still exist
â”‚
â”œâ”€ Device Change Listener (useEffect)
â”‚  â”œâ”€ addEventListener('devicechange')
â”‚  â””â”€ Re-enumerate on user plug/unplug
â”‚
â”œâ”€ Permission Handling
â”‚  â”œâ”€ Check if device labels visible (indicates 'granted')
â”‚  â”œâ”€ requestPermissions() calls getUserMedia()
â”‚  â”‚  â”œâ”€ Requests video: true, audio: true
â”‚  â”‚  â”œâ”€ Stops tracks immediately
â”‚  â”‚  â””â”€ Updates permission status
â”‚  â””â”€ Graceful fallback if 'denied'
â”‚
â””â”€ Selection Validation
   â”œâ”€ setSelectedCameraId(id)
   â”‚  â”œâ”€ Validates id exists in cameras[]
   â”‚  â”œâ”€ Saves to localStorage
   â”‚  â””â”€ Warns if device not found
   â””â”€ setSelectedMicId(id)
      â”œâ”€ Validates id exists in microphones[]
      â”œâ”€ Saves to localStorage
      â””â”€ Warns if device not found
```

### System Audio Capture (macOS 13.2+)

```
useSystemAudioCapture Hook
â”‚
â”œâ”€ Platform Detection (on mount)
â”‚  â”œâ”€ supportsSystemAudio() checks macOS version >= 13.2
â”‚  â””â”€ getSystemAudioSupportMessage() provides fallback message
â”‚
â”œâ”€ startCapture(screenSourceId)
â”‚  â”‚
â”‚  â”œâ”€ Call captureSystemAudio() from audio-capture-utils
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ Request desktop capture WITH audio flag (ScreenCaptureKit)
â”‚  â”‚  â”‚  â””â”€ Minimal 1x1px video requested (only need audio)
â”‚  â”‚  â”œâ”€ Extract audio track from combined stream
â”‚  â”‚  â””â”€ Stop dummy video track, return audio-only stream
â”‚  â”‚
â”‚  â”œâ”€ Setup audio level metering (Web Audio API)
â”‚  â”‚  â”œâ”€ Create AudioContext
â”‚  â”‚  â”œâ”€ Create AnalyserNode with fftSize=2048
â”‚  â”‚  â””â”€ Connect stream â†’ analyser
â”‚  â”‚
â”‚  â””â”€ Start updateAudioLevel() animation frame loop
â”‚
â”œâ”€ startRecording()
â”‚  â”œâ”€ Create MediaRecorder from audio stream
â”‚  â”œâ”€ Set bitrate: 192 kbps for high quality
â”‚  â””â”€ Begin recording with 1 second data chunks
â”‚
â”œâ”€ stopRecording() (timeout-protected)
â”‚  â”œâ”€ Stop MediaRecorder with 5 second timeout
â”‚  â”œâ”€ Collect chunks into Blob
â”‚  â””â”€ Return audio blob for IPC storage
â”‚
â””â”€ stopCapture()
   â”œâ”€ Cancel animation frame loop
   â”œâ”€ Close AudioContext
   â”œâ”€ Stop all media tracks
   â””â”€ Reset state

Audio Capture Utils Shared Module (src/lib/audio-capture-utils.ts)
â”‚
â”œâ”€ captureSystemAudio(screenSourceId)
â”‚  â””â”€ Extract audio from ScreenCaptureKit desktop capture
â”‚
â”œâ”€ setupAudioLevelMeter(stream)
â”‚  â””â”€ Create Web Audio API analyser for real-time metering
â”‚
â”œâ”€ getAudioLevel(analyser)
â”‚  â””â”€ Calculate FFT-based level (0-100 scale)
â”‚
â”œâ”€ cleanupAudioResources(resources)
â”‚  â””â”€ Safe cleanup of AudioContext and MediaStream
â”‚
â””â”€ stopMediaRecorderSafely(recorder, chunks, mimeType)
   â””â”€ Stop with timeout protection (5 second default)
```

### Platform Detection

```
supportsSystemAudio()
â”‚
â””â”€ getMacOSVersion()
   â”œâ”€ Parse navigator.userAgent
   â”‚  â””â”€ Extract "Mac OS X 14_2" pattern
   â”œâ”€ Return { major: 14, minor: 2 }
   â”‚
   â””â”€ Compare version >= 13.2
      â”œâ”€ macOS 14.x+ â†’ true (system audio supported)
      â”œâ”€ macOS 13.2+ â†’ true (Ventura with ScreenCaptureKit)
      â””â”€ Earlier versions â†’ false

getSystemAudioSupportMessage()
â”‚
â””â”€ Returns user-friendly message
   â”œâ”€ macOS < 13.2: "macOS Ventura (13.2+) required for system audio"
   â””â”€ Non-macOS: "System audio capture only supported on macOS"
```

## Storage Architecture

### localStorage Keys

| Key | Purpose | Type | Default |
|-----|---------|------|---------|
| `openscreen:selectedCameraId` | Last selected camera | string \| null | null |
| `openscreen:selectedMicId` | Last selected microphone | string \| null | null |
| `openscreen:systemAudioEnabled` | System audio preference | boolean | false |

**Lifecycle**:
- Loaded on app start by useMediaDevices hook
- Updated when user changes selection
- Validated on load (device still exists?)
- Cleared if device unplugged

## Type System

### Media Device Types

```typescript
// From navigator.mediaDevices.enumerateDevices()
interface MediaDeviceInfo {
  deviceId: string;        // Unique identifier
  groupId: string;         // Related I/O devices group
  kind: 'videoinput' | 'audioinput' | 'audiooutput';
  label: string;           // Human-readable name (requires permission)
}

// Hook return type
interface UseMediaDevicesReturn {
  cameras: MediaDeviceInfo[];
  microphones: MediaDeviceInfo[];
  selectedCameraId: string | null;
  selectedMicId: string | null;
  systemAudioEnabled: boolean;
  systemAudioSupported: boolean;
  permissionStatus: 'granted' | 'denied' | 'prompt' | 'unknown';
  isLoading: boolean;
  error: string | null;
  setSelectedCameraId(id: string | null): void;
  setSelectedMicId(id: string | null): void;
  setSystemAudioEnabled(enabled: boolean): void;
  refreshDevices(): Promise<void>;
  requestPermissions(): Promise<boolean>;
}
```

### Camera Recording Types

```typescript
// Screen recorder options with optional camera recording
interface ScreenRecorderOptions {
  sourceId: string;
  deviceIds: MediaDeviceIds;
  cameraDeviceId?: string | null;  // Optional camera device ID
  onError?: (error: Error) => void;
}

// Camera PiP overlay configuration (Phase 3)
interface CameraPipConfig {
  enabled: boolean;                    // Toggle PiP overlay on/off
  position: 'top-left' | 'top-right' | 'bottom-left' | 'bottom-right';
  size: 'small' | 'medium' | 'large';  // Relative to container width
  borderRadius: number;                // Percentage (0-100): 0=square, 50=circle
}

// Size presets (percentage of container width)
const CAMERA_PIP_SIZE_PRESETS = {
  small: 15,    // 15% of container width
  medium: 22,   // 22% of container width
  large: 30,    // 30% of container width
}
```

## IPC Message Protocol

### Recording Control

```
Client â†’ Main: { type: 'START_CAPTURE', payload: { sourceId, deviceIds, cameraDeviceId? } }
Main â†’ Client: { type: 'CAPTURE_FRAME', payload: ArrayBuffer }
Main â†’ Client: { type: 'CAPTURE_STATUS', payload: { frame, timestamp } }
Client â†’ Main: { type: 'STOP_CAPTURE' }
Main â†’ Client: { type: 'CAPTURE_END', payload: { filepath, duration } }
```

### Audio Recording Storage

```
Microphone Audio:
Client â†’ Main: { type: 'store-audio-recording', payload: { audioData: ArrayBuffer, fileName: string } }
Main â†’ Client: { type: 'store-audio-recording-result', payload: { success: boolean, path: string } }

System Audio (macOS 13.2+ only):
Client â†’ Main: { type: 'store-system-audio-recording', payload: { audioData: ArrayBuffer, fileName: string } }
Main â†’ Client: { type: 'store-system-audio-recording-result', payload: { success: boolean, path: string } }

Security Measures:
- Path validation: Resolved path must be within RECORDINGS_DIR
- Filename validation: Pattern `(mic|system-audio)-\\d{13,14}\\.[a-z0-9]+`
- File size limits: 100MB max for each audio file
- Directory traversal protection with path.startsWith() check
```

### Camera Recording Storage

```
Client â†’ Main: { type: 'store-camera-recording', payload: { videoData: ArrayBuffer, fileName: string } }
Main â†’ Client: { type: 'store-camera-recording-result', payload: { success: boolean, path: string } }
```

### Audio/Video Path Resolution

```
Camera Video Path:
Client â†’ Main: { type: 'get-camera-video-path', payload: mainVideoPath }
Main â†’ Client: { type: 'get-camera-video-path-result', payload: { success: boolean, path: string | null } }

Microphone Audio Path (Phase 06):
Client â†’ Main: { type: 'get-mic-audio-path', payload: mainVideoPath }
Main â†’ Client: { type: 'get-mic-audio-path-result', payload: { success: boolean, path: string | null } }

System Audio Path (Phase 06):
Client â†’ Main: { type: 'get-system-audio-path', payload: mainVideoPath }
Main â†’ Client: { type: 'get-system-audio-path-result', payload: { success: boolean, path: string | null } }
```

**Details**:
- Pattern matching: `recording-{timestamp}.webm` â†’ `camera|mic|system-audio-{timestamp}.webm`
- Returns null if file doesn't exist (track was not recorded)
- Used in VideoEditor.buildMediaTracks() to construct timeline tracks
- **Security**: Path validation prevents directory traversal attacks
  - Resolved path must be within RECORDINGS_DIR
  - Check: `path.startsWith(RECORDINGS_DIR + path.sep)`
  - File existence verified before returning path
  - Filename pattern validation ensures only valid audio files processed

### Export Pipeline

```
Client â†’ Main: { type: 'EXPORT_VIDEO', payload: { format, settings } }
Main â†’ Client: { type: 'EXPORT_PROGRESS', payload: { progress, current, total } }
Main â†’ Client: { type: 'EXPORT_COMPLETE', payload: { filepath } }
Main â†’ Client: { type: 'EXPORT_ERROR', payload: { message } }
```

## Error Handling

### Device Enumeration Errors

| Error | Cause | Recovery |
|-------|-------|----------|
| `NotAllowedError` | Permission denied | Show permission dialog, ask user to retry |
| `NotFoundError` | No devices present | Show message, allow retry when device plugged in |
| `TypeError` | API not available | Fall back to default device, continue |

### Validation Errors

| Error | Cause | Recovery |
|-------|-------|----------|
| Device not found | Device unplugged | Clear selection, use next available |
| Invalid device ID | Corrupted localStorage | Remove entry, use next available |

## Performance Considerations

### Media Device Enumeration
- **Cost**: ~50-100ms to enumerate devices
- **Optimization**: Debounce 'devicechange' events
- **Caching**: Keep device list in state, update on events only

### Canvas Rendering (PixiJS)
- **Target FPS**: 30-60 depending on video
- **Optimization**: Off-screen rendering, use textures for frames
- **Memory**: Cap texture cache to prevent leaks

### Export Pipeline
- **Bottleneck**: Frame encoding and audio muxing
- **Optimization**: Web Worker for frame processing
- **Memory**: Stream frames instead of loading entire video

## Security Considerations

### Media Access
- Only request permissions when user initiates action
- Request both camera and microphone together
- Stop tracks immediately after permission check
- Don't store MediaStream objects (security risk)

### Storage
- localStorage is per-origin (safe for device selection)
- Device IDs are persistent but non-sensitive
- No authentication tokens or secrets in storage

### File Operations
- All file I/O goes through main process IPC
- Validate file paths before writing
- Use safe save dialogs for user selection

## Deployment Architecture

### Build Process

```
Development:
  npm run dev
  â”œâ”€ Vite dev server (HMR)
  â”œâ”€ Electron main process with debugger
  â””â”€ Live reload of React components

Production:
  npm run build
  â”œâ”€ TypeScript compilation (src/)
  â”œâ”€ Vite bundling (React app)
  â”œâ”€ Electron main process build
  â”œâ”€ electron-builder packaging
  â”‚  â”œâ”€ macOS: .dmg installer
  â”‚  â”œâ”€ Windows: .msi installer
  â”‚  â””â”€ Linux: AppImage
  â””â”€ Code signing (macOS/Windows)
```

### Platform-Specific Notes

**macOS**:
- System audio capture requires macOS 13.2+ (ScreenCaptureKit)
- User agent parsing: "Mac OS X 14_2" or "Mac OS X 14.2"
- Built with electron-builder for .dmg distribution

**Windows**:
- All media APIs available
- Built with electron-builder for .msi installer

**Linux**:
- All media APIs available
- Built with electron-builder for AppImage

## Future Architecture Enhancements

1. **Multi-track Timeline** - Support stacking multiple recordings
2. **Audio Effects** - EQ, compression, normalization per track
3. **Video Effects** - Filters, blur, text overlays
4. **Keyboard Shortcuts** - Full keyboard navigation
5. **Plugin System** - Third-party filters and effects
